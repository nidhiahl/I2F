{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f91b331-45e6-427b-b188-09d128ab563b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skmultiflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21054/775437620.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPCB_iForest_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCB_EIF\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCB_EIF_Window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/i2f/our_pcbif/PCB_iForest_modules/PCB_EIF.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mNDKSWIN\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNDKSWIN\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mndk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/i2f/our_pcbif/PCB_iForest_modules/NDKSWIN.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskmultiflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrift_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_drift_detector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseDriftDetector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skmultiflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "from statistics import mean\n",
    "\n",
    "from PCB_iForest_modules.PCB_EIF import PCB_EIF_Window\n",
    "\n",
    "INF_value = 1519889160.0* 100000\n",
    "\n",
    "pcb_param_list = {\n",
    "# PCB-iForest\n",
    "'window_size' : 200,\n",
    "'num_trees' : 100,\n",
    "'extension_level' : 1.0, # in percent of dimension - 1.0 denotes to fully extended version\n",
    "'anomaly_threshold_eif' : 0.5,\n",
    "# NDKSWIN-Parameters\n",
    "'alpha' : 0.01,\n",
    "'n_dimensions' : 1,\n",
    "'n_tested_samples' : 0.1,\n",
    "'stat_size' : 30\n",
    "}\n",
    "\n",
    "def load_data(dataFile: str):\n",
    "    '''\n",
    "    return data\n",
    "    @param dataFile: path to the file\n",
    "    @return: data\n",
    "    '''\n",
    "    df = pd.read_csv(dataFile,sep=' ')\n",
    "    class_labels = df.iloc[:, -1:]\n",
    "    final_df = df.astype(float)\n",
    "    data_with_labels = final_df.to_numpy()\n",
    "    return data_with_labels\n",
    "\n",
    "def preprocessing_data(data: np.ndarray):\n",
    "    '''\n",
    "    handling remaining nan, inf values in data instance; separating the class labels from data instance\n",
    "    @param data: numpy array\n",
    "    @return: data, class label\n",
    "    '''\n",
    "    data = data.tolist()\n",
    "    y_label = data[-1]\n",
    "    if isinstance(y_label, str):\n",
    "        if y_label !=  \"Benign\": #anomalous point is represented as 1\n",
    "            y_label = 1\n",
    "\n",
    "        else:\n",
    "            y_label = 0\n",
    "\n",
    "    x_data = np.asarray(data[:-1])\n",
    "    x_data = np.nan_to_num(x_data, nan=0.0, posinf= INF_value,\n",
    "                         neginf=-INF_value)\n",
    "\n",
    "    return x_data, y_label\n",
    "\n",
    "\n",
    "\n",
    "dataset_name = \"shuttle\"\n",
    "update_type = \"U1\"   #U1 or U2\n",
    "D0_path = \"./datasets/\"+dataset_name+\"/\"+update_type+\"/D0.csv\"\n",
    "deltaD_path = \"./datasets/\"+dataset_name+\"/\"+update_type+\"/deltaD.csv\"\n",
    "\n",
    "D0 = load_data(D0_path)\n",
    "deltaD = load_data(deltaD_path)\n",
    "D0_size = len(D0)\n",
    "deltaD_size = len(deltaD)\n",
    "\n",
    "\n",
    "data = np.concatenate((D0,deltaD))\n",
    "\n",
    "len(data)\n",
    "\n",
    "print(D0_size, deltaD_size)\n",
    "\n",
    "print(\"D0 shape: \", data.shape)\n",
    "extension = 1.0  # in percent of dimension - 1.0 denotes to fully extended version\n",
    "print(\"extension: \", extension)\n",
    "\n",
    "threshold_EIF = 0.5\n",
    "num_dimensions = 1\n",
    "num_samples = 0.1\n",
    "outlier_content_seen =0\n",
    "\n",
    "\n",
    "hyper_parameters = [[128,100]]\n",
    "list_of_mean_F1_scores = []\n",
    "list_of_mean_exec_times = []\n",
    "list_of_mean_AUC = []\n",
    "list_of_feature_scores_PCB_IBFS = list()\n",
    "\n",
    "for params in hyper_parameters:\n",
    "    dict_key = \"W\" + str(params[0]) + \"_T\" + str(params[1])\n",
    "    list_of_all_F1_scores = []\n",
    "    list_of_all_exec_times = []\n",
    "    list_of_all_AUC = []\n",
    "    print(\"classifier PCBIF processing \"+ dataset_name + \" with hyper_parameters \" + dict_key)\n",
    "\n",
    "    num_iteration = 1\n",
    "    for i in range(num_iteration):\n",
    "        random_state = np.random.RandomState(i)\n",
    "        initial_time = time.time()\n",
    "        predicted_results = []\n",
    "        true_outliers = []\n",
    "        true_positives = 0\n",
    "        false_positives = 0\n",
    "        true_negatives  = 0\n",
    "        false_negatives = 0\n",
    "        samples_used = 0\n",
    "        epsilon = 0.00000001  #small +ve value\n",
    "        PCB_iForest = PCB_EIF_Window(dimension=data.shape[1], window_size=pcb_param_list['window_size'],\n",
    "                                                     num_trees=pcb_param_list['num_trees'],\n",
    "                                                     anomaly_threshold=pcb_param_list['anomaly_threshold_eif'],\n",
    "                                                     extension_level=int(\n",
    "                                                         pcb_param_list['extension_level'] * data.shape[1] - 2),  # -2 here since label column is still contained in data\n",
    "                                                     initial_data_size = D0_size,\n",
    "                                                     alpha=pcb_param_list['alpha'],\n",
    "                                                     n_dimensions=pcb_param_list['n_dimensions'],\n",
    "                                                     n_tested_samples=pcb_param_list['n_tested_samples'],\n",
    "                                                     stat_size=pcb_param_list['stat_size'])\n",
    "        \n",
    "        for data_instance in D0:\n",
    "            samples_used += 1\n",
    "            x_instance, y_instance = preprocessing_data(data_instance)\n",
    "            if y_instance == 1:\n",
    "                true_outliers.append(y_instance)\n",
    "            PCB_iForest.run_train_classifier(x_instance)\n",
    "            '''\n",
    "            predicted_value = PCB_iForest.give_prediction()\n",
    "            predicted_results.append(predicted_value)\n",
    "\n",
    "            if y_instance   == 1:\n",
    "                if predicted_value == 1:\n",
    "                    true_positives +=1\n",
    "                else:\n",
    "                    false_negatives +=1\n",
    "            else:\n",
    "                if predicted_value == 1:\n",
    "                    false_positives +=1\n",
    "                else:\n",
    "                    true_negatives +=1\n",
    "\n",
    "        outlier_content_seen = (len(true_outliers)/samples_used) * 100\n",
    "'''\n",
    "        \n",
    "        for data_instance in D0:\n",
    "            samples_used += 1\n",
    "            x_instance, y_instance = preprocessing_data(data_instance)\n",
    "            if y_instance == 1:\n",
    "                true_outliers.append(y_instance)\n",
    "            #predicted_value = PCB_iForest.predict(x_instance)\n",
    "            predicted_value = PCB_iForest.give_prediction(x_instance)\n",
    "            #PCB_iForest.hello()\n",
    "            predicted_results.append(predicted_value)\n",
    "\n",
    "            if y_instance   == 1:\n",
    "                if predicted_value == 1:\n",
    "                    true_positives +=1\n",
    "                else:\n",
    "                    false_negatives +=1\n",
    "            else:\n",
    "                if predicted_value == 1:\n",
    "                    false_positives +=1\n",
    "                else:\n",
    "                    true_negatives +=1\n",
    "\n",
    "        outlier_content_seen = (len(true_outliers)/samples_used) * 100        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"Total no. of samples: \",samples_used)\n",
    "        print(\"outliers content percentage in data: \",outlier_content_seen)\n",
    "        print(\"true_positives={},false_positives={},false_negatives={},true_negatives={}\".format(true_positives,false_positives,false_negatives,true_negatives))\n",
    "\n",
    "        try:\n",
    "                            false_positives_rate = false_positives / (false_positives + true_negatives)\n",
    "        except ZeroDivisionError:\n",
    "                            false_positives_rate = epsilon\n",
    "\n",
    "        try:\n",
    "                            false_negatives_rate = false_negatives / (true_positives + false_negatives)\n",
    "        except ZeroDivisionError:\n",
    "                            false_negatives_rate = epsilon\n",
    "\n",
    "        try:\n",
    "                            recall = true_positives / (\n",
    "                                        true_positives + false_negatives)  # Sensitivity (aka recall, True Positive Rate)\n",
    "        except ZeroDivisionError:\n",
    "                            recall = epsilon\n",
    "\n",
    "        try:\n",
    "                            specificity = true_negatives / (false_positives + true_negatives)  # Specificity (aka True Negative Rate)\n",
    "        except ZeroDivisionError:\n",
    "                            specificity = epsilon\n",
    "\n",
    "        try:\n",
    "                            precision = true_positives / (true_positives + false_positives)  # Precision\n",
    "        except ZeroDivisionError:\n",
    "                            precision = epsilon\n",
    "\n",
    "        try:\n",
    "                            f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        except ZeroDivisionError:\n",
    "                            f1_score = epsilon\n",
    "\n",
    "        AUC = (1.0 + recall - false_positives_rate) / 2.0\n",
    "\n",
    "        print(\"Prediction_metrics:\\nrecall={},false_positives_rate={},\\nfalse_negatives_rate={},specificity={},\\nf1_score={}, precision={},\\nAUC={}\".format(recall,false_positives_rate,false_negatives_rate,specificity,f1_score,precision,AUC))\n",
    "        final_time = time.time()\n",
    "        diff = final_time - initial_time\n",
    "        print(\"total runtime: \", diff)\n",
    "        print(\"Average runtime per instance: \",diff/samples_used)\n",
    "\n",
    "        list_of_all_F1_scores.append(f1_score)\n",
    "        list_of_all_exec_times.append(diff)\n",
    "        list_of_all_AUC.append(AUC)\n",
    "\n",
    "        \n",
    "\n",
    "    mean_F1_Score = mean(list_of_all_F1_scores)\n",
    "    mean_exec_time = mean(list_of_all_exec_times)\n",
    "    mean_AUC = mean(list_of_all_AUC)\n",
    "    list_of_mean_F1_scores.append({dict_key:mean_F1_Score})\n",
    "    list_of_mean_exec_times.append({dict_key:mean_exec_time})\n",
    "    list_of_mean_AUC.append({dict_key: mean_AUC})\n",
    "\n",
    "    print(\"Hyperparameter: \" + dict_key + \"\\n\")\n",
    "    for score in list_of_all_F1_scores:\n",
    "        print(json.dumps(score))\n",
    "    print(\"Average F1_score: \",json.dumps(mean_F1_Score, indent=2)+ \"\\n\\n\")\n",
    "\n",
    "    for element in list_of_all_AUC:\n",
    "        print(json.dumps(element))\n",
    "    print(\"Average AUC: \",json.dumps(mean_AUC, indent=2) + \"\\n\\n\")\n",
    "\n",
    "    for element in list_of_all_exec_times:\n",
    "        print(json.dumps(element))\n",
    "    print(\"Average runtime: \",json.dumps(mean_exec_time,indent=2)+ \"\\n\\n\")\n",
    "    print(\"========================================================================================\" + \"\\n\")\n",
    "\n",
    "\n",
    "    with open(result_filename,\"a\") as f:\n",
    "        f.write(\"*************************************%s mean evaluation results***********************************\\n\\n\" %model)\n",
    "        f.write(\"\\nnum of runs: %s\" % num_iteration)\n",
    "        f.write(\"\\noutliers content percentage in data: %s \" % outlier_content_seen)\n",
    "        f.write(\"\\nNDKSWIN parameters: No. of dimensions: %s, No. of samples tested: %s\" % (num_dimensions,num_samples))\n",
    "        f.write(\"\\nModel name: %s\" % model)\n",
    "        if model == \"PCB_EIF\":\n",
    "            f.write(\"\\nextension level : %s\" % extension)\n",
    "            f.write(\"\\nanomaly threshold: %s \"% threshold_EIF)\n",
    "        else:\n",
    "            f.write(\"\\nanomaly threshold: %s \" % threshold_IBFS)\n",
    "        f.write(\"\\nDataset: %s \"% dataFile)\n",
    "        f.write(\"\\ndata shape: %s\" % str(data.shape))\n",
    "        f.write(\"\\n\\nHyperparameter : mean_F1_score\")\n",
    "        for score in list_of_mean_F1_scores:\n",
    "            f.write(json.dumps(score,sort_keys=True,indent=2) + \"\\n\")\n",
    "\n",
    "        f.write(\"Hyperparameter : mean_AUC\")\n",
    "        for element in list_of_mean_AUC:\n",
    "            f.write(json.dumps(element, sort_keys=True, indent=2) + \"\\n\")\n",
    "\n",
    "        f.write(\"Hyperparameter : mean_exec_time\")\n",
    "        for element in list_of_mean_exec_times:\n",
    "            f.write(json.dumps(element, sort_keys=True, indent=2) + \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4a82e-d6ce-4b4e-908b-1c6f9a0eaa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier PCBIF processing Shuttle.csv with hyper_parameters W128_T100\n",
    "\n",
    "\n",
    "Total no. of samples:  20000\n",
    "outliers content percentage in data:  7.095\n",
    "true_positives=1382,false_positives=362,false_negatives=37,true_negatives=18219\n",
    "Prediction_metrics:\n",
    "recall=0.9739252995066948,false_positives_rate=0.01948226683170981,\n",
    "false_negatives_rate=0.026074700493305146,specificity=0.9805177331682902,\n",
    "f1_score=0.8738539361365794, precision=0.7924311926605505,\n",
    "AUC=0.9772215163374925\n",
    "total runtime:  35.47285771369934\n",
    "Average runtime per instance:  0.001773642885684967\n",
    "Hyperparameter: W128_T100\n",
    "\n",
    "0.8738539361365794\n",
    "Average F1_score:  0.8738539361365794\n",
    "\n",
    "\n",
    "0.9772215163374925\n",
    "Average AUC:  0.9772215163374925\n",
    "\n",
    "\n",
    "35.47285771369934\n",
    "Average runtime:  35.47285771369934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c24651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [3,4,5,6,7,8,8,9,5,3,3,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9682f8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "803cdf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6ee92df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0342c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df.index)] = ['Amy', 89, 93]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab068c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amy</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2\n",
       "0  Amy  89  93"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff732d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
